{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNPxOC8IBLvr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install fsspec==2023.6.0\n",
        "!pip install git+https://github.com/huggingface/transformers@4.54.0.dev0\n",
        "!python -m pip install matplotlib==3.10.0"
      ],
      "metadata": {
        "id": "jVGliGk674CI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from datasets import Dataset, DatasetDict\n",
        "from matplotlib.lines import Line2D\n",
        "import pickle, os\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "PfpJx4PQ76ow"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QQvAlweSEyOu"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"<Project Folder>\""
      ],
      "metadata": {
        "id": "DHhugR3DzKt5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRThiwkdEtgb"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/blog/modernbert\n",
        "\n",
        "model_id = \"answerdotai/ModernBERT-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset = Dataset.from_json(os.path.join(BASE_DIR, \"data/dataset.jsonl\"))"
      ],
      "metadata": {
        "id": "A2b5MuzqzTKX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x8LT3tpLFMHI"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "for i in range(len(hf_dataset)):\n",
        "  labels.extend(hf_dataset[i][\"str_label\"])\n",
        "\n",
        "labels = list(set(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQq3wDliFOLW"
      },
      "outputs": [],
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit([labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gj0ZpnPVFRsS"
      },
      "outputs": [],
      "source": [
        "id2label = {idx:label for idx, label in enumerate(mlb.classes_)}\n",
        "label2id = {label:idx for idx, label in enumerate(mlb.classes_)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold_datasets = []\n",
        "for i in range(5):\n",
        "  kfold_datasets.append(DatasetDict.load_from_disk(os.path.join(BASE_DIR, \"data/k_fold_ds\", f\"{i}-fold\")))"
      ],
      "metadata": {
        "id": "1-8k_W0nunyJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ITS Dataset Evaluation"
      ],
      "metadata": {
        "id": "9gidR8Db1Iwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operating Point Selection Algorithm for Multi-Label Binary Classifiers"
      ],
      "metadata": {
        "id": "YzhEhrLnzf5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Computes the sigmoid function for a given input x.\n",
        "    Can handle scalars, arrays, or matrices due to NumPy's capabilities.\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "bpXxfj5zSoIe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=None, # This output_dir is where the predictions will be saved if you use predict()\n",
        "    log_level=\"error\",\n",
        "    per_device_eval_batch_size=8, # Use an appropriate batch size for inference\n",
        "    disable_tqdm=False,\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "dd-w4yL2Gp2t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = os.path.join(BASE_DIR, \"output\")\n",
        "kfold_checkpoint_folder = [folder for folder in os.listdir(output_folder) if folder.startswith(\"kfold_checkpoints\")][0]\n",
        "kfold_checkpoint_full_path = os.path.join(output_folder, kfold_checkpoint_folder)\n",
        "five_model_checkpoints = [os.path.join(kfold_checkpoint_full_path, fold) for fold in os.listdir(kfold_checkpoint_full_path) if os.path.isdir(os.path.join(kfold_checkpoint_full_path, fold))]\n",
        "five_model_checkpoints"
      ],
      "metadata": {
        "id": "80l2kVnqDgZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "valid_set_outputs = []\n",
        "for idx in range(5):\n",
        "  loaded_model = AutoModelForSequenceClassification.from_pretrained(five_model_checkpoints[idx], problem_type=\"multi_label_classification\", num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)\n",
        "  predictor = Trainer(model=loaded_model, args=args, tokenizer=tokenizer)\n",
        "\n",
        "  valid_split = kfold_datasets[idx][\"valid\"]\n",
        "\n",
        "  # Element of the `valid_set_outputs`contains:\n",
        "  #   - predictions: numpy array of logits\n",
        "  #   - label_ids: numpy array of original labels (if available in the dataset)\n",
        "  #   - metrics: dictionary of evaluation metrics (if compute_metrics was defined and run)\n",
        "  valid_set_outputs.append(predictor.predict(valid_split))"
      ],
      "metadata": {
        "id": "tu-1qIM4FQcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_set_probs = [sigmoid(valid_pred.predictions) for valid_pred in valid_set_outputs]\n",
        "valid_true_labels = [valid_pred.label_ids for valid_pred in valid_set_outputs]"
      ],
      "metadata": {
        "id": "wlAuFVE9IGnv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_binary_predictions(probabilities, threshold):\n",
        "    probabilities = np.array(probabilities)\n",
        "    binary_predictions = (probabilities >= threshold).astype(int)\n",
        "\n",
        "    return binary_predictions"
      ],
      "metadata": {
        "id": "_agcomccBfK4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Operating Point Selection Algorithm for Multi-Label Binary Classifiers**\n",
        "\n",
        "We propose an operating points selection algorithm tailored for binary classifiers within a multi-label classification framework, employing a **5-fold cross-validation strategy**.\n",
        "\n",
        "For each fold and each label, the algorithm performs the following steps:\n",
        "\n",
        "1. **ROC Curve Derivation:**\n",
        "\n",
        "  * The Receiver Operating Characteristic (ROC) curve is derived from the validation set probability scores and corresponding ground-truth labels.\n",
        "\n",
        "  * This yields False Positive Rates (FPRs), True Positive Rates (TPRs), and associated thresholds.\n",
        "\n",
        "2. **F1 Score Computation:**\n",
        "\n",
        " * Subsequently, the F1 score is computed for each threshold by applying binarization to the prediction scores and evaluating against the true labels.\n",
        "\n",
        "3. **Optimal Operating Point Identification:**\n",
        "\n",
        " * The operating point achieving the **maximum F1 score** is identified.\n",
        "\n",
        " * **Tie-breaking Mechanism:**\n",
        "\n",
        "    * In instances of a unique maximum, it is selected outright.\n",
        "\n",
        "    * For ties—wherein multiple thresholds yield equivalent maximum F1 scores—the algorithm resolves ambiguity by selecting the operating point corresponding to the **highest TPR** among candidates. This emphasizes sensitivity while preserving an optimal balance between precision and recall.\n",
        "\n",
        "This methodology yields fold- and label-specific thresholds optimized for validation performance to facilitate subsequent model evaluation processes."
      ],
      "metadata": {
        "id": "ntedH8xuDNTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "operating_points_for_all_folds = []\n",
        "\n",
        "for i in range(5):\n",
        "  operating_points = []\n",
        "  for j in range(len(labels)):\n",
        "    f1_scores = []\n",
        "    scores = valid_set_probs[i][:, j]\n",
        "    y_true = valid_true_labels[i][:, j]\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    thresholds = thresholds.tolist()\n",
        "\n",
        "    for threshold in thresholds:\n",
        "      y_pred = get_binary_predictions(scores, threshold)\n",
        "      f1_scores.append(f1_score(y_true, y_pred))\n",
        "\n",
        "    roc_data = {\n",
        "        'fpr': fpr,\n",
        "        'tpr': tpr,\n",
        "        'thresholds': thresholds,\n",
        "        'f1_scores': f1_scores\n",
        "    }\n",
        "\n",
        "    max_element = max(f1_scores)\n",
        "    indices = [index for index, value in enumerate(f1_scores) if value == max_element]\n",
        "    if len(indices) == 1:\n",
        "      idx = indices[0]\n",
        "      operating_points.append(thresholds[idx])\n",
        "    else:\n",
        "      candidate_thresholds = []\n",
        "      candidate_tpr = []\n",
        "      for idx in indices:\n",
        "        candidate_thresholds.append(thresholds[idx])\n",
        "        candidate_tpr.append(tpr[idx])\n",
        "\n",
        "      max_tpr_idx = candidate_tpr.index(max(candidate_tpr))\n",
        "      operating_points.append(candidate_thresholds[max_tpr_idx])\n",
        "\n",
        "  operating_points_for_all_folds.append(operating_points)"
      ],
      "metadata": {
        "id": "8_Hztcs6TL__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Precision, Recall and F1 score"
      ],
      "metadata": {
        "id": "Zv6E4ZyTYOth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "test_set_outputs = []\n",
        "for idx in range(5):\n",
        "  loaded_model = AutoModelForSequenceClassification.from_pretrained(five_model_checkpoints[idx], problem_type=\"multi_label_classification\", num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)\n",
        "  predictor = Trainer(model=loaded_model, args=args, tokenizer=tokenizer)\n",
        "\n",
        "  test_split = kfold_datasets[idx][\"test\"]\n",
        "\n",
        "  # Element of the `test_set_outputs`contains:\n",
        "  #   - predictions: numpy array of logits\n",
        "  #   - label_ids: numpy array of original labels (if available in the dataset)\n",
        "  #   - metrics: dictionary of evaluation metrics (if compute_metrics was defined and run)\n",
        "  test_set_outputs.append(predictor.predict(test_split))"
      ],
      "metadata": {
        "id": "OUsl3iANYTii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precisions_micro = []\n",
        "recalls_micro = []\n",
        "f1_scores_micro = []\n",
        "\n",
        "for idx, output in enumerate(test_set_outputs):\n",
        "  probs = sigmoid(output.predictions)\n",
        "  y_true = output.label_ids\n",
        "  y_pred = []\n",
        "  for j in range(len(labels)):\n",
        "    y_pred.append(get_binary_predictions(probs[:,j], operating_points_for_all_folds[idx][j]))\n",
        "\n",
        "  y_pred = np.array(y_pred).T\n",
        "\n",
        "  overlap = (y_pred & y_true.astype(int)).sum(1)\n",
        "\n",
        "  precisions_micro.append(precision_score(y_true, y_pred, average=\"micro\", zero_division=0))\n",
        "  recalls_micro.append(recall_score(y_true, y_pred, average=\"micro\", zero_division=0))\n",
        "  f1_scores_micro.append(f1_score(y_true, y_pred, average=\"micro\"))\n",
        "\n",
        "\n",
        "print(f\"precision_<micro>: {np.mean(precisions_micro)}\")\n",
        "print(f\"recall_<micro>:    {np.mean(recalls_micro)}\")\n",
        "print(f\"f1_scores_<micro>:   {np.mean(f1_scores_micro)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAglQSi8adSq",
        "outputId": "85ff7292-2d9b-4767-9aa5-e48253d5e0be"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision_<micro>: 0.7428576222228833\n",
            "recall_<micro>:    0.7629318805968361\n",
            "f1_scores_<micro>:   0.752123596574215\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L1aD9YveGdmC",
        "qsht-8YBZxUp"
      ],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}